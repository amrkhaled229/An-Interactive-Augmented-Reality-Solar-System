# AR Interactive Solar System

### An Educational App for Middle School Students


## Overview

This project is an Augmented Reality (AR) application aimed at middle school students to provide an interactive and immersive learning experience of the solar system. By leveraging advanced Human-Computer Interaction (HCI) techniques, students can explore and interact with 3D models of planets, learn about their features, and understand the science behind them in a fun and engaging way.

The project integrates multiple cutting-edge technologies such as gesture and facial recognition, object detection, gaze tracking, and more to create a seamless and interactive AR learning environment.

## Key Features

- **TUIO Markers + GUI**: Displays 3D objects of planets when the camera targets specific TUIO shapes, providing an interactive learning experience.
- **Sockets & Bluetooth**: Ensures smooth communication between devices and platforms.
- **Context Awareness**: Adjusts the educational content and interactivity based on user behavior and environmental factors.
- **MediaPipe + Gesture Recognition**: Allows users to interact with the virtual solar system through hand gestures.
- **Face Detection & Facial Recognition**: Customizes the AR experience for each user.
- **YOLO Object Detection**: Detects relevant objects in the environment to enhance interaction.
- **Emotion & Gaze Tracking**: Adapts the app experience based on the student’s engagement and emotional responses.
- **Unity**: Powering the entire AR experience with seamless graphics and interaction.

## Target Audience

This app is built for middle school students, providing an engaging and educational way to explore the solar system. Students can interact with the planets in real-time, enhancing their understanding of space science.

## Technologies Used

- **Unity** for building the AR environment
- **TUIO** for marker tracking
- **Sockets** for network communication
- **Bluetooth** for device interactivity
- **MediaPipe** for hand gesture recognition
- **YOLO** for object detection
- **Gaze and Emotion Tracking** for personalized interactions

## Installation

1. Clone the repository:
    ```bash
    git clone https://github.com/An-Interactive-Augmented-Reality-Solar-System.git
    ```
2. Open the project in Unity.
3. Build and run the application on your AR device.

## Usage

- Point your camera at the TUIO markers to start interacting with the solar system.
- Use hand gestures to rotate, zoom, or select planets.
- Gaze at planets to get more detailed information about them.
- The system will adapt to your engagement and provide personalized feedback.

## Team Members

- **Amr Khaled** – Lead Developer
- **[Other team members]** – [Roles of the team members]

## Future Improvements

- Adding more celestial objects and space phenomena.
- Expanding gesture recognition capabilities.
- Incorporating voice commands for an even more interactive experience.

## Contributing

Contributions are welcome! Please feel free to submit a pull request or raise issues for feature suggestions and bug fixes.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
